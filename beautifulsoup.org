* 웹문서에서 정보 추출하기

웹 페이지를 수집한 후에, 웹 페이지 내에서 원하는 정보를 추출하는 방법에 대해서 알아봅니다.


** HTML 파일의 구조

HTML은 Hyper-text Markup Language로, 문서 표현 언어의 하나입니다. 인터넷 문서들의 대부분이 이 언어로 이루어져 있죠.

HTML의 구조를 이해하면 필요한 정보를 추출하는데 도움이 됩니다.


#+BEGIN_SRC html
<html>
    <head>
    </head>

    <body>
        <div id="main-container" style="color: black;">This is a container</div>
        <div class="article header">Webpage scrapying</div>
    </body>
</html>
#+END_SRC


** 태그

HTML은 전반적으로 태그로 이루어져 있습니다. 태그란 =<html></html>= 처럼, 괄호(=<>=) 사이에 태그 이름이 들어가고, 태그는 태그 열기(=<html>=)와 태그 닫기(=</html>=)로 이루어져 있습니다. 태그 사이에는 다른 태그가 들어올 수도 있고 최종 문자열 값이 들어올 수도 있습니다.

태그의 종류에는 여러 가지가 있는데, 웹 페이지에서 정보를 추출할 때 눈여겨볼만한 유용한 태그는 다음과 같은 것들이 있습니다.

 - div
 - span
 - p

태그에는 속성이 기재될 수 있습니다. 속성은 태그명 뒤에 자리잡고, 속성명과 값으로 이루어져 있습니다. (ex. ~id="main-container"~)

웹 페이지 추출에서 유용한 속성의 종류에는 다음과 같은 것들이 있습니다.

 - id
 - class
 - style


** CSS Selector

커다란 HTML 문서에서 내가 원하는 정보가 있는 위치를 어떻게 지칭할 수 있을까요? 모든 줄을 검사하면서 특정 문자열이 포함된 줄을 포착할 수도 있겠지만, 조금 더 쉬운 방법들이 있습니다. 그중, 웹에서 jquery 라이브러리가 등장한 이후로는 CSS selector를 지정하는 방법이 많이 사용됩니다.

가장 많이 활용되는 CSS selector 의 기본 형태는 아래와 같은 것들이 있습니다:

 - ~div~: 모든 =div= 태그를 선택
 - ~div#main-container~: =div= 중, =id= 가 =main-container= 인 =div= 만을 선택
 - ~div.header~: =div= 중, =class= 가 =header= 인 =div= 들만을 선택
 - ~div[style="color: black;"]~: =div= 중, =style= 이라는 속성이 =color: black;= 이라는 값을 가지는 =div= 만을 선택

그런데, 위의 selector만으로는 지정하기 어려운 경우가 있습니다. 아래와 같은 [[https://www.w3.org/TR/css3-selectors/#combinators][combinator selector]]를 사용하면, 웬만한 경우는 처리할 수 있습니다:

 - ~div.header li~: =div.header= 태그 하위에 있는 모든 =li= 를 선택
 - ~div.header > ul~: =div.header= 태그의 1단계 하위에 있는 모든 =ul= 를 선택
 - ~div.header li:nth-child(2)~: =div.header= 태그 하위에 있는 태그 중, =li= 가 2번째 자식인 모든 =li= 를 선택
 - ~div.header li:first-child~: =div.header= 태그 하위에 있는 태그 중, =li= 가 첫번째 자식인 모든 =li= 를 선택
 - ~div.header li:last-child~: =div.header= 태그 하위에 있는 태그 중, =li= 가 마지막 자식인 모든 =li= 를 선택


#+BEGIN_SRC html
<html>
    <head>
    </head>

    <body>
        <div id="main-container" style="color: black;">This is a container</div>
        <div class="article header">Webpage scrapying <a href="http://jsoup.org">Visit JSoup!</a></div>
    </body>
</html>
#+END_SRC

위의 HTML 코드에서, =This is a container= 라는 문자열을 지칭하는 CSS selector는 아래와 같습니다.

#+BEGIN_SRC css
div#main-container
#+END_SRC

=div= 태그 중에서, =main-container= 라는 id 값을 가지고 있는 것을 지칭합니다.

=Webpage scrapying= 이라는 문자열을 지칭하는 CSS selector는 아래와 같습니다.


#+BEGIN_SRC css
div.article
#+END_SRC

그 중에서 =Visit JSoup!= 이라는 문자열을 지칭하는 CSS selector는 아래와 같습니다.

#+BEGIN_SRC css
div.article > a
#+END_SRC


** BeautifulSoup

[[https://www.crummy.com/software/BeautifulSoup/bs4/doc/][BeautifulSoup]]은 웹 페이지 내에서 원하는 문서 구성 요소를 CSS selector 형식으로 특정할 수 있도록 도와줍니다.

BeautifulSoup은 외부 라이브러리이지만, Anaconda에 기본적으로 포함되어 있기 때문에 별도로 설치할 필요는 없습니다. Anaconda를 사용하지 않고 순수 Python 배포본을 사용하는 경우에는 아래와 같이 설치할 수 있습니다.

#+BEGIN_SRC sh
pip install beautifulsoup4
#+END_SRC

BeautifulSoup에는 다양한 메소드들이 있는데, CSS selector를 사용하기 위해서는 ~select()~ 메소드를 사용합니다.

#+BEGIN_SRC python :exports both :results output
  from bs4 import BeautifulSoup

  html = '''<html>
      <head>
      </head>

      <body>
          <div id="main-container" style="color: black;">This is a container</div>
          <div class="article header">Webpage scrapying</div>
      </body>
  </html>
  '''

  soup = BeautifulSoup(html)      # BeautifulSoup에 문서를 적재합니다
  print(soup.select('#main-container')[0].string)
  print(soup.select('#main-container')[0]['style'])
  print(soup.select('.article')[0].string)
  print(soup.select('.article')[0]['class'])
#+END_SRC

#+RESULTS:
: This is a container
: color: black;
: Webpage scrapying
: ['article', 'header']

각 element에 대해서는 ~string~ 속성을 통해 값을 참조할 수 있고, ~dict~ 처럼 ~[]~ 참조를 통해 각 속성에 접근할 수 있습니다.


** 연습문제

연습문제로 아래 URL의 HTML에서 정보를 추출해보겠습니다. 아래의 URL은 다음 아고라의 주소입니다. 여기에서 글 제목과 글쓴이, 글의 URL 주소를 가져오겠습니다.

http://bbs3.agora.media.daum.net/gaia/do/petition/list?bbsId=P001&objCate1=1

우선 위의 URL에 접속한 후, Chrome에서 개발자 도구를 엽니다. Ctrl-Shift-I를 누릅니다. Elements 탭에서 돋보기 아이콘을 선택한 후, 확인하고자 하는 HTML 요소를 클릭합니다. 해당 요소를 특정할 수 있는 태그 및 속성을 확인합니다.

글 제목을 클릭해보면, =span= 이라는 태그가 =sbj= 클래스(~<span class="sbj">~)를 가지고 있는 것을 볼 수 있습니다. 그리고 그 아래에 =a= 태그에 제목 문자열이 들어있습니다. 따라서 제목을 지칭하는 CSS selector는 다음과 같이 쓸 수 있습니다.


#+BEGIN_SRC css
span.sbj > a
#+END_SRC

개발자 도구의 Console 탭에서 ~$$('span.sbj > a')~ 라고 입력해봅시다.

이와 비슷하게, 글쓴이를 지칭하는 CSS selector는 다음과 같이 쓸 수 있습니다.

#+BEGIN_SRC css
span.sbj > span.name > a
#+END_SRC

개발자 도구의 Console 탭에서 ~$$('span.sbj > span.name > a')~ 라고 입력해봅시다.


이러한 CSS selector를 사용하여, 아고라 글의 제목과 글쓴이, 글의 URL 주소를 가져오는 코드는 다음과 같습니다.


#+BEGIN_SRC python :results output :exports both
  import requests
  from bs4 import BeautifulSoup

  url = 'http://bbs3.agora.media.daum.net/gaia/do/petition/list?pageIndex=1&bbsId=P001&objCate1=1'

  response = requests.get(url)
  soup = BeautifulSoup(response.content)
  subjects = soup.select('span.sbj > a')
  date = soup.select('span.date')
  counts = soup.select('span.cnt > em')
  writers = soup.select('span.sbj > span.name > a')

  entries = zip(subjects, date, counts, writers)

  for subject, date, count, writer in entries:
      _subject = subject.string
      _date = date.string
      _writer = writer.string
      _count = count.string
      href = subject.attrs['href']

      print('|'.join([_subject, _date, _writer, _count, href]))
#+END_SRC

#+RESULTS:
#+begin_example
문재인 대통령의 파렴치 범죄, 확실한 물증|2017.12.28 11:36|사과사|0|read?bbsId=P001&objCate1=1&articleId=211736&pageIndex=1
공휴일을 유급휴일로 바꾸어야합니다.|2017.12.28 11:17|한가닥의 빛|0|read?bbsId=P001&objCate1=1&articleId=211735&pageIndex=1
강경화 딸.. 국적회복 확인하자..|2017.12.28 10:20|정광수|1|read?bbsId=P001&objCate1=1&articleId=211732&pageIndex=1
벌레같은 교도관들이 뼈를 부러뜨리고 성폭행을 하는 등|2017.12.28 10:06|악덕교도관대청소|2|read?bbsId=P001&objCate1=1&articleId=211731&pageIndex=1
광명 운산고 김Y숙 선생의 명예퇴직을 반대합니다!|2017.12.28 08:57|RainSun|1|read?bbsId=P001&objCate1=1&articleId=211730&pageIndex=1
근로복지공단은 당장 꼼수를 멈추라!|2017.12.28 06:16|풍경소리|4|read?bbsId=P001&objCate1=1&articleId=211729&pageIndex=1
삼성화재보험 중소기업상대로 사기행각|2017.12.28 06:01|이천곤|2|read?bbsId=P001&objCate1=1&articleId=211728&pageIndex=1
학교 규칙이라는 구실로 휴대폰 수거를 하지 말아주십시오|2017.12.28 02:57|전승훈|0|read?bbsId=P001&objCate1=1&articleId=211726&pageIndex=1
지배자들|2017.12.28 01:01|deadkillers-society|1|read?bbsId=P001&objCate1=1&articleId=211725&pageIndex=1
사이보그 이리역 폭파 시멘틱스|2017.12.28 00:11|deadkillers-society|0|read?bbsId=P001&objCate1=1&articleId=211724&pageIndex=1
사이보그 데이터 베이스 킬 입증|2017.12.28 00:09|deadkillers-society|0|read?bbsId=P001&objCate1=1&articleId=211723&pageIndex=1
제2 imf, 살인의 추억 재현될 수 있습니다!|2017.12.27 23:40|deadkillers-society|0|read?bbsId=P001&objCate1=1&articleId=211722&pageIndex=1
[국민감사] 대법원이 국민을 우롱하고 있습니다. 442|2017.12.27 23:33|서재황|0|read?bbsId=P001&objCate1=1&articleId=211721&pageIndex=1
[국민감사] 대법원이 국민을 우롱하고 있습니다. 441|2017.12.27 23:30|서재황|0|read?bbsId=P001&objCate1=1&articleId=211720&pageIndex=1
어린이집 평가인증 부모가 할수 있게해주세요 |2017.12.27 22:27|허브향기ㆀ|0|read?bbsId=P001&objCate1=1&articleId=211719&pageIndex=1
이재용 부회장을 선처해 주십시오. |2017.12.27 21:28|sunny|0|read?bbsId=P001&objCate1=1&articleId=211718&pageIndex=1
교황님 살펴주세요|2017.12.27 20:16|ww8401|0|read?bbsId=P001&objCate1=1&articleId=211717&pageIndex=1
무고죄로 처벌해 주세요|2017.12.27 18:44|tiger|0|read?bbsId=P001&objCate1=1&articleId=211716&pageIndex=1
무고죄로 처벌해 주세요|2017.12.27 18:40|tiger|0|read?bbsId=P001&objCate1=1&articleId=211715&pageIndex=1
고이와 1987, 이걸 누가 샀을까?! 고이비도요?|2017.12.27 17:35|deadkillers-society|0|read?bbsId=P001&objCate1=1&articleId=211714&pageIndex=1
#+end_example

아래의 나무위키 URL에 대해서, 위키 내부간의 하이퍼링크 목록을 추출해보세요.

https://namu.wiki/w/Python


#+BEGIN_SRC python :results output :exports result 
  import requests
  from bs4 import BeautifulSoup

  def visit_page(page):
      name, href = page
      url = 'https://namu.wiki' + href
      response = requests.get(url)
      soup = BeautifulSoup(response.content, 'html5lib')
      link_elements = soup.select('.wiki-inner-content .wiki-link-internal')
      links = set([(elem['title'], elem['href']) for elem in link_elements])
      return list(links)

  page = ('Python', '/w/Python')
  print([name for name, page in visit_page(page)])
#+END_SRC


#+BEGIN_EXAMPLE
['명령어', '코엑스', '페리아 연대기', '국부론', '넘파이', 'Swift(프로그래밍 언어)', '스택', 'C언어', '파일:xkcdpythonko.png', '2015년', '연세대학교', '킹덤 언더 파이어', '한국', '스팸(몬티 파이선 스케치)', 'Bottle', 'Erlang', 'APAC', '파이선', '비단뱀', 'Pygame', '창조', 'Django', '코드', 'JDK', '오라클', '부산대학교', '필로우', 'C#', '아스키', '인천대학교', 'callback 함수', '웹 프레임워크', 'Pillow', '프레임워크', '액션스크립트', 'rm -rf /', '카이스트', '심즈 4', 'scikit-learn', '고자', '드롭박스', '파일:나무위키+유도.png', '파이톤', 'tkinter', 'Flask', 'Lua', '부르즈 할리파', '추가바람', '의사코드', '파이썬', 'JIT', '상암', '라이브러리', '프로세스', 'reddit', '코더', '프로그래밍 언어', '나무위키:프로젝트', 'MATLAB', '시드 마이어의 문명', '2016년', 'Ruby', 'PyPy', 'Perl', 'Linux', '리눅스', 'PyGame', '우분투', 'C', '누리꿈스퀘어', 'C++', 'NumPy', '스레드', 'Haskell', '파이게임', '스크래피', 'Beautiful Soup', '이스터 에그', '파일:external/regmedia.co.uk/swift_benchmark.jpg', 'Scrapy', 'OpenCV', '문명 4', '자바 가상 머신', '기계학습', 'Sublime Text', '통합 개발 환경', '중국', 'Go', '42', '프로그래머', 'EVE 온라인', '2014년', '스택 오버플로우', '뱀', '국민대학교', '구조체', 'Notepad++', '인스타그램', 'IBM', '몬티 파이선', '한글', 'LISP', 'JAVA', 'Java', '유튜브', 'xkcd', 'WOW', 'R(프로그래밍 언어)', '2017년', '객체 지향 프로그래밍', 'UC 버클리', 'JavaScript', '뷰티플 수프', '월드 오브 탱크', '코루틴', '이클립스(통합 개발 환경)', 'C(프로그래밍 언어)', '비주얼 스튜디오', "Ren'Py", '상명대학교', '구글', 'JVM', '매사추세츠 공과대학교']
#+END_EXAMPLE

이번에는 위의 내용을 응용해서, snowballing 방식으로 웹페이지를 수집해보세요.

#+BEGIN_SRC ipython :session :results output raw :exports none :ipyfile outputs/beautifulsoup-manuwiki-python-map.png
  %matplotlib inline
  import os
  import requests
  import networkx as nx
  import matplotlib.pyplot as plt
  from bs4 import BeautifulSoup

  def visit_page(page):
      name, href = page
      url = 'https://namu.wiki' + href
      response = requests.get(url)
      soup = BeautifulSoup(response.content, 'html5lib')
      link_elements = soup.select('.wiki-inner-content .wiki-link-internal')
      links = set([(elem['title'], elem['href']) for elem in link_elements])
      return list(links)

  def save_edges(fout, page, links):
      for link in links:
          fout.write('\t'.join([page[0], page[1], link[0], link[1]]))
          fout.write('\n')

  def crawl(seed, fout):
      visited = set()
      page = seed.pop()
      if page not in visited:
          links = visit_page(page)
          visited.add(page)
          save_edges(fout, page, links)
          seed = seed + links

      while seed:
          page = seed.pop()
          if page not in visited and (not page[0].startswith('파일:') and not page[0].startswith('나무위키:')):
              links = visit_page(page)
              visited.add(page)
              save_edges(fout, page, links)

  def load_graph(graph, fin):
      for line in fin:
          src_name, _, tgt_name, _ = line.strip().split('\t')
          graph.add_edge(src_name, tgt_name)

  def remove_zero_outdegree(graph):
      nodes_to_remove = [name for name, freq in G.out_degree if freq == 0]
      for node in nodes_to_remove:
          graph.remove_node(node)

  def remove_one_indegree(graph):
      nodes_to_remove = [name for name, freq in G.in_degree if freq < 2]
      for node in nodes_to_remove:
          graph.remove_node(node)

  def show_graph(graph):
      pos = nx.kamada_kawai_layout(graph)
      plt.figure(figsize=(12, 12))    # 결과 이미지 크기를 크게 지정 (12inch * 12inch)
      nx.draw_networkx_edges(graph, pos, alpha=0.1);
      nx.draw_networkx_labels(graph, pos, font_family='Noto Sans CJK KR'); # 각자 시스템에 따라 적절한 폰트 이름으로 변경
      plt.show()
#+END_SRC

#+BEGIN_SRC ipython :session :results raw :exports none
  seed = [('Python', '/w/Python')]
  with open(os.path.join('outputs', 'namuwiki.txt'), 'w', encoding='utf8') as fout:
      crawl(seed, fout)
#+END_SRC

#+BEGIN_SRC ipython :session :results raw :exports both :ipyfile outputs/beautifulsoup-namu-pagelinks.png
  %matplotlib inline
  import os
  import networkx as nx

  G = nx.DiGraph()
  with open(os.path.join('outputs', 'namuwiki.txt'), encoding='utf8') as fin:
      load_graph(G, fin)

  remove_zero_outdegree(G)
  remove_one_indegree(G)
  show_graph(G)
#+END_SRC

#+RESULTS:
[[file:outputs/beautifulsoup-namu-pagelinks.png]]


** Ajax & JSON

요즘 만들어지는 웹사이트들 중에는, HTML로 모두 미리 작성되는 대신, 서버로부터는 데이터만을 받고 웹브라우저에서 동적으로 HTML 문서 구조를 생성하는 경우가 많습니다. 이렇게 서버로부터 데이터를 받을 때 사용하는 데이터의 형식으로 최근 많이 사용되는 것이 JSON(Javascript Simple Object Notation)입니다. JSON은 아래와 같은 모양을 가집니다.

#+BEGIN_SRC javascript
  {
    'people': [
      {'name': 'Tom', 'age': 23},
      {'name': 'John', 'age': 30}
    ]
  }
#+END_SRC

가만히 보면 Python에서 ~list~ 나 ~dict~ 을 표현하는 방식과 비슷하게 보이지 않나요? 실제로 ~requests~ 라이브러리에서는 JSON 형식을 python의 ~dict~ 와 ~list~ 형태로 변환해서 반환합니다.

Tistory의 예를 한번 살펴볼까요?

아래 URL은 IT/인터넷 카테고리에 새로 올라온 글을 보여주는 페이지의 주소입니다.

http://tistory.com/category/it/internet

크롬 웹브라우저에서 페이지를 방문해서 개발자 도구로 =Network= 탭을 살펴보면, 아래 URL이 실제 글 목록 내용을 담고 있는 문서라는 것을 알 수 있습니다.

http://tistory.com/category/getMoreCategoryPost.json

실제 내용을 살펴볼까요?

#+BEGIN_SRC javascript
  {
    "error":false,
    "data":{
      "lastPublished":1514558042000,
      "list":[
        {"daumLikeUid":"2856430_14","title":"LEC. 01 : 파이썬 시작","summary":"프로그래밍 언어를 가장 빨리 익히는 방법은 역시 Learn by doing, 직접 타이핑하고 실행해보면서 익히는 것이다. 그렇다고해서 아무런 사전지식 없이 바로 코딩을 시작 하는 것 보다 전체적인 내용을 빠르게 훑고 관심있는 예제 코드를 작성하고 실행해보면서 모르는 부분을 찾아보는 것이 훨씬 효율적일 것이다. 지금부터 파이썬을 머릿속에 정리해보자. 1. 파이..","userName":"대봉씨","categoryName":"IT 인터넷","thumbnail":"","url":"http://daebongssi.tistory.com/14","best":false,"likeCount":0,"published":"2017.12.29 23:48","encodedTitle":"LEC.%2001%20%3A%20%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%8B%9C%EC%9E%91"},
        {"daumLikeUid":"2745913_15","title":"[알고리즘] 백준 8958번 OX퀴즈 재도전","summary":"수요일에 풀어본 백준 8958번 OX문제를 다시 풀어보았으나 도저히 풀리지 않아서 결국 다른 블로그 https://fatc.club/2017/03/01/991 에서 코드를 긁어오게되었습니다.ㅠㅠㅠㅠ 이런식으로 코드를 짤 수 있다고 하는데요 내일 플이에 대한 설명을 덧붙이도록 하겠습니다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34..","userName":"bae_wang","categoryName":"IT 인터넷","thumbnail":"","url":"http://blue-wnag.tistory.com/15","best":false,"likeCount":0,"published":"2017.12.29 23:48","encodedTitle":"%5B%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%5D%20%EB%B0%B1%EC%A4%80%208958%EB%B2%88%20OX%ED%80%B4%EC%A6%88%20%EC%9E%AC%EB%8F%84%EC%A0%84"},
        {"daumLikeUid":"2771216_174","title":"컴퓨터 공인인증서 위치 및 삭제 방법","summary":"인터넷 뱅킹을 하거나 공공기관 홈페이지에 접속하는 경우에는 공인인증서가 반드시 필요합니다. 그런데 내 컴퓨터에 저장되어 있는 공인인증서를 복사하거나 삭제해야 하는 경우가 생깁니다. 그럼 이제부터 컴퓨터 공인인증서 위치 및 삭제 방법에 대하여 알아보겠습니다. 컴퓨터 공인인증서 위치 및 삭제 방법 컴퓨터를 교체하거나 윈도우를 재설치할 때 공인인..","userName":"미네르바 올..","categoryName":"IT 인터넷","thumbnail":"http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile21.uf.tistory.com%2Fimage%2F9924F14B5A465470141FB5","url":"http://smart365.tistory.com/174","best":false,"likeCount":0,"published":"2017.12.29 23:46","encodedTitle":"%EC%BB%B4%ED%93%A8%ED%84%B0%20%EA%B3%B5%EC%9D%B8%EC%9D%B8%EC%A6%9D%EC%84%9C%20%EC%9C%84%EC%B9%98%20%EB%B0%8F%20%EC%82%AD%EC%A0%9C%20%EB%B0%A9%EB%B2%95"}
      ],
      "category":"it/internet"
    }
  }
#+END_SRC

Python의 자료구조 표현형과 대부분 유사하지만, ~false~ 라고 표현되어 있는 부분은 약간 다릅니다. Python에서는 ~False~ 라고 표현해야 합니다. 이 외에도 Python에서의 ~None~ 을 javascript에서는 ~null~ 이라고 표현하는 등, 약간의 차이점은 있지만, 전반적으로는 이해하는데 큰 무리가 없습니다.

웹페이지에서 서버로부터 정보를 받아오는 과정을 관찰하고, 그 요청 질의를 모방해서 아래와 같이 정보를 Python에서 직접 받아올 수 있습니다.

#+BEGIN_SRC python :exports both :results output
  import requests

  headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:58.0) Gecko/20100101 Firefox/58.0',
             'T-Ajax': '151455907333',
             'X-Requested-With': 'XMLHttpRequest'}
  cookies = {'TISTORY_THEME_ORDER': 'recent'}
  data = {'category': 'it/internet',
          'first': True,
          'lastPublished': 0,
          'order': 'recent'}
  response = requests.post('http://tistory.com/category/getMoreCategoryPost.json', data=data, headers=headers, cookies=cookies)
  print(response.json())
#+END_SRC

#+RESULTS:
: {'error': False, 'data': {'lastPublished': 1514558912000, 'category': 'it/internet', 'list': [{'userName': 'zamezzz', 'url': 'http://zamezzz.tistory.com/231', 'published': '2017.12.30 00:03', 'best': False, 'encodedTitle': '%5B%EC%8A%A4%ED%94%84%EB%A7%81%20%232%5D%20%EC%A0%9C%EC%96%B4%EC%9D%98%20%EC%97%AD%EC%A0%84%28IoC%29', 'thumbnail': '', 'daumLikeUid': '2399904_231', 'likeCount': 0, 'summary': '■ 스프링 #2. 제어의 역전 (IoC) ● 제어의 역전(IoC)란 ? 제어의 역전이란 일반적인 제어 구조와는 달리, 오브젝트가 자신이 사용할 오브젝트를 생성, 관계 설정, 사용등의 제어를 직접 하지 않습니다. 이러한 제어 권한을 다른 대상에게 위임하여, 위임받은 오브젝트가 이 모든 제어 권한을 갖도록 합니다. 스프링이 제어권을 가지고 직접 만들고 관계를 부여하는 ..', 'categoryName': 'IT 인터넷', 'title': '[스프링 #2] 제어의 역전(IoC)'}, {'userName': ':evEnt:', 'url': 'http://hottestissue.club/272', 'published': '2017.12.30 00:02', 'best': False, 'encodedTitle': '%EA%B0%80%EC%83%81%ED%99%94%ED%8F%90%20%EC%BD%94%EC%9D%B8%EC%9A%A9%EC%96%B4%20%EC%A0%95%EB%A6%AC', 'thumbnail': 'http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile27.uf.tistory.com%2Fimage%2F99EB36445A4657151C4AB5', 'daumLikeUid': '2536944_272', 'likeCount': 0, 'summary': '가상화폐 코인 용어 정리 (참고: 코인판, 네이버 백과사전) 김프 : 김치프리미엄, 국내가격이 해외가격보다 높을때 쓰는 말입니다. 역프 : 해외가격이 국내 가격보다 높을때 쓰는 말입니다. 떡상 : 미친듯이 코인가격이 상승할때 쓰는 단어입니다. 떡락 : 미친듯이 코인가격이 하락할때 쓰는 단어입니다. 추매 : 추격매수, 가격이 막 오르는데 추가로 코인을 사는 것을 ..', 'categoryName': 'IT 인터넷', 'title': '가상화폐 코인용어 정리'}, {'userName': 'robinjoon', 'url': 'http://robinjoon.tistory.com/3', 'published': '2017.12.30 00:01', 'best': False, 'encodedTitle': '%5B%EC%9E%90%EB%B0%94%5D%20try%20catch%EB%AC%B8', 'thumbnail': '', 'daumLikeUid': '2852920_3', 'likeCount': 0, 'summary': '예외 발생시 무한반복하는 코드는 어떻게 짜야 할까? 다음과 같이 while문으로 묶고 try 맨 밑에 break을 해주면 된다. 다음: while(true) { try{ Scanner input=new Scanner(System.in); ret=input.nextInt(); input.close(); break; }catch(Exception E){ System.err.println(E); } }', 'categoryName': 'IT 인터넷', 'title': '[자바] try catch문'}, {'userName': '현승태', 'url': 'http://anthellproject1.tistory.com/567', 'published': '2017.12.30 00:00', 'best': False, 'encodedTitle': '%EC%97%B0%EC%B0%A8%EC%88%98%EB%8B%B9%20%EA%B3%84%EC%82%B0%EA%B8%B0%20%EB%AC%B4%EB%A3%8C%20%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%20%EB%B0%A9%EB%B2%95', 'thumbnail': '', 'daumLikeUid': '2374366_567', 'likeCount': 0, 'summary': '연차수당 계산기 무료 사용하는 방법 연차수당을 자동 계산 해 주는 계산기를 사용 하는 방법에 대해 설명 해 드리겠습니다. 회사를 탐험 하기 시작 하면 연례 이라고 칭하는 무슨이 윈도우조 되었다. 근무 연수에 따라 적용 됩니다. 해마다 사용 하지 않는 경우 ♡ 년도 분 (1 ~ 3 월)에 보조로 급하게 되어 있습니다. 따라서 대부분의 기업에서는 연간을 모두 추방 ..', 'categoryName': 'IT 인터넷', 'title': '연차수당 계산기 무료 사용하는 방법'}, {'userName': '사랑공장공..', 'url': 'http://joojoocompany.tistory.com/455', 'published': '2017.12.30 00:00', 'best': False, 'encodedTitle': 'PDF%20%EB%B7%B0%EC%96%B4%20%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C%20%ED%95%98%EB%8A%94%20%EB%B0%A9%EB%B2%95', 'thumbnail': 'http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F99A4933F5A4495D026F664', 'daumLikeUid': '2115266_455', 'likeCount': 0, 'summary': 'PDF 뷰어 다운로드 하는 방법 회사의 소개서 , 제품설명서 , 카다로그 등의 문서를 파일로 만들때 PDF 파일로 저장들 많이 하실텐데요 이 PDF 파일을 보기 위해선 꼭! PDF 뷰어 프로그램이 있어야해요 PDF 뷰어 편집용은 유료이고 그냥 PDF 뷰어용은 무료인거 다들 알고계시죠? 무료로 PDF 뷰어용 다운로드를 할수있는 URL 링크 하나 걸어드릴테니 이곳에서 P..', 'categoryName': 'IT 인터넷', 'title': 'PDF 뷰어 다운로드 하는 방법'}, {'userName': '화이트그리..', 'url': 'http://whitegrifin.tistory.com/580', 'published': '2017.12.29 23:56', 'best': False, 'encodedTitle': '%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%86%A1%20%EA%B3%84%EC%A0%95%EC%B0%BE%EA%B8%B0', 'thumbnail': 'http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile6.uf.tistory.com%2Fimage%2F99AD9C455A46423111E325', 'daumLikeUid': '1868813_580', 'likeCount': 0, 'summary': "카카오톡 계정찾기 국내에서 가장 많은 분들이 사용하고 있는 메신저는 'kakao talk'일 것이다. 사용하기가 쉽고, 다양한 서비스를 갖췄기 때문이 아닐까 생각한다. 새로운 휴대폰을 구입하거나, 계정의 비밀번호 또는 아이디가 기억이 나지 않을때 해결방법으로 '카카오톡 계정찾기'방법에 대해 알아볼까 한다. 카카오톡 계정찾기 방법으로는? 모바일 또는 PC 환경..", 'categoryName': 'IT 인터넷', 'title': '카카오톡 계정찾기'}, {'userName': '통신전문가 ..', 'url': 'http://biz0320.tistory.com/501', 'published': '2017.12.29 23:54', 'best': False, 'encodedTitle': '%EC%82%AC%EB%AC%B4%EC%8B%A4%EC%9D%B8%ED%84%B0%EB%84%B7%EC%A0%84%ED%99%94%EA%B8%B0%20%ED%95%A9%EB%A6%AC%EC%A0%81%EC%9D%B8%20%EB%B9%84%EC%9A%A9%EC%9C%BC%EB%A1%9C%20%EC%84%A4%EC%B9%98%20%EB%B0%9B%EC%9C%BC%EC%84%B8..', 'thumbnail': 'http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile6.uf.tistory.com%2Fimage%2F9999DE435A4656DC345468', 'daumLikeUid': '1766796_501', 'likeCount': 0, 'summary': '사무실인터넷전화기 합리적인 비용으로 설치 받으세요. 안녕하세요. 언제나 원활한 업무를 위해 사무실인터넷전화기 및 다양한 통신기기들을 안정적인 환경으로 구축해 드리면서도 합리적인 비용으로 설치 할 수 있도록 지원해 드리는 이팀장 입니다. 신규 사업장은 물론이며 사무실을 이전하게 되는 경우나 확장 및 리모델링이 필요할 때 사무실인터넷전화기 설..', 'categoryName': 'IT 인터넷', 'title': '사무실인터넷전화기 합리적인 비용으로 설치 받으세..'}, {'userName': '한초Hancho', 'url': 'http://hancho1111.tistory.com/84', 'published': '2017.12.29 23:54', 'best': False, 'encodedTitle': '%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%86%A1%20%EB%8C%80%ED%99%94%EB%82%B4%EC%9A%A9%20%EB%B0%B1%EC%97%85%ED%95%98%EB%8A%94%20%EB%B0%A9%EB%B2%95', 'thumbnail': 'http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile24.uf.tistory.com%2Fimage%2F99BB663D5A4652503155DD', 'daumLikeUid': '2788581_84', 'likeCount': 0, 'summary': '카카오톡 채팅방 대화내용 백업을 위해 카카오톡 설정으로 이동해 주세요! 채팅을 터치해 주세요! 대화 백업을 터치해 주세요. 대화 백업하기를 터치해 주세요. 복원할때 사용할 비밀번호를 입력해 주세요! (참고로 너무 오래된 채팅내용은 백업되지 않습니다) 재설치후 전화번호 인증-카카오계정 로그인 할때 백업한 카카오 계정에 로그인해야 복구 가능합니다.', 'categoryName': 'IT 인터넷', 'title': '카카오톡 대화내용 백업하는 방법'}, {'userName': '', 'url': 'http://gmbang.tistory.com/entry/네이버-미디어-플레이어-라이브-방송보기', 'published': '2017.12.29 23:52', 'best': False, 'encodedTitle': '%EB%84%A4%EC%9D%B4%EB%B2%84%20%EB%AF%B8%EB%94%94%EC%96%B4%20%ED%94%8C%EB%A0%88%EC%9D%B4%EC%96%B4%20%EB%9D%BC%EC%9D%B4%EB%B8%8C%20%EB%B0%A9%EC%86%A1%EB%B3%B4%EA%B8%B0', 'thumbnail': 'http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile30.uf.tistory.com%2Fimage%2F99A2573E5A46537B1A121A', 'daumLikeUid': '2827420_140', 'likeCount': 0, 'summary': '네이버 미디어 플레이어 라이브 실시간 방송보기. 이번 추천 소프트웨어에서는 네이버 미디어 플레이어를 통해 라이브 방송을 실시간으로 볼 수 있는 방법에 대해 안내하도록 하겠습니다. 네이버 미디어 플레이어는 네이버에서 제공하는 동영상 재생기 인데요. 네이버 라이브 방송보기도 가능해서 많은 인기를 가지고 있었습니다. 하지만 최신버전의 네이버 비디어..', 'categoryName': 'IT 인터넷', 'title': '네이버 미디어 플레이어 라이브 방송보기'}, {'userName': 'Realsung', 'url': 'http://realsung.tistory.com/73', 'published': '2017.12.29 23:51', 'best': False, 'encodedTitle': '%5BCodeUp%201054%5D%EB%91%98%20%EB%8B%A4%20%EC%B0%B8%EC%9D%BC%20%EA%B2%BD%EC%9A%B0%EB%A7%8C%20%EC%B0%B8%20%EC%B6%9C%EB%A0%A5%ED%95%98%EA%B8%B0', 'thumbnail': '', 'daumLikeUid': '2849738_73', 'likeCount': 0, 'summary': '논리연산자 && 는 주어진 2개의 논리값이 모두 참(1) 일 때에 1(참)으로 계산하고, 이외의 경우에는 0(거짓) 으로 계산한다. 이러한 논리 연산을 AND 연산이라고도 부르고, ·로 표시하거나 생략하며, 집합 기호로는 ∩(교집합, intersection) 의미한다. 모두 같은 의미이다. 참, 거짓의 논리값(boolean value, 불 값을 다루어주는 논리연산자는 !(not), &&(and), ||(..', 'categoryName': 'IT 인터넷', 'title': '[CodeUp 1054]둘 다 참일 경우만 참 출력하기'}, {'userName': 'JANGGO', 'url': 'http://free2cash.tistory.com/102', 'published': '2017.12.29 23:50', 'best': False, 'encodedTitle': '%EC%A7%80%EB%8B%88%20%EC%9E%90%EB%8F%99%EA%B2%B0%EC%A0%9C%20%ED%95%B4%EC%A7%80%EB%B0%A9%EB%B2%95%20%EA%B0%84%EB%8B%A8%20%ED%95%B4%EA%B2%B0', 'thumbnail': 'http://img1.daumcdn.net/thumb/C295x191.fjpg/?scode=mtistory&fname=http%3A%2F%2Fcfile30.uf.tistory.com%2Fimage%2F992BC13D5A4655A217C146', 'daumLikeUid': '2822877_102', 'likeCount': 0, 'summary': '지니는 멜론과 더불어 국내에서 가장 인기있는 음악 스트리밍 서비스 중 하나입니다. 국내 대중가요는 물론이고 POP, 동요 등 다양한 분야의 음악이 제공되어 많은 사람들이 사용하고 있습니다. 그런데 지니는 기본적으로 정액제를 기반으로 서비스되기 때문에, 사용을 안할 때는 반드시 정액제를 해지해야 혹시나 있을 수 있는 불이익을 방지할 수 있습니다. 일단 ..', 'categoryName': 'IT 인터넷', 'title': '지니 자동결제 해지방법 간단 해결'}, {'userName': '대봉씨', 'url': 'http://daebongssi.tistory.com/entry/LEC-01-파이썬-시작', 'published': '2017.12.29 23:48', 'best': False, 'encodedTitle': 'LEC.%2001%20%3A%20%ED%8C%8C%EC%9D%B4%EC%8D%AC%20%EC%8B%9C%EC%9E%91', 'thumbnail': '', 'daumLikeUid': '2856430_14', 'likeCount': 0, 'summary': '프로그래밍 언어를 가장 빨리 익히는 방법은 역시 Learn by doing, 직접 타이핑하고 실행해보면서 익히는 것이다. 그렇다고해서 아무런 사전지식 없이 바로 코딩을 시작 하는 것 보다 전체적인 내용을 빠르게 훑고 관심있는 예제 코드를 작성하고 실행해보면서 모르는 부분을 찾아보는 것이 훨씬 효율적일 것이다. 지금부터 파이썬을 머릿속에 정리해보자. 1. 파이..', 'categoryName': 'IT 인터넷', 'title': 'LEC. 01 : 파이썬 시작'}]}}

하지만 실제 모던 웹 방식으로 만들어진 웹사이트, 또는 로그인이 필요한 웹사이트 등에서 정보를 가져오는 것은 쉽지 않은 경우도 많습니다. 최근 웹 개발 기술에 대한 상당히 복잡한 지식을 필요로 하는 경우도 많이 있습니다.
